{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3498e5-5da4-4ba1-82e9-c3ddd607664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements in original data: 856170\n",
      "Required elements for reshaping: 7420140\n",
      "The total number of elements does not match the required number for reshaping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "train_csv = \"features_fixed.csv\"\n",
    "dev_csv   = r\"C:\\LibriSpeech\\features_dev_fixed.csv\"\n",
    "test_csv  = r\"C:\\LibriSpeech\\features_test_fixed.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_dev = pd.read_csv(dev_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "\n",
    "\n",
    "features = [\n",
    "    'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', \n",
    "    'MFCC_8', 'MFCC_9', 'MFCC_10', 'MFCC_11', 'MFCC_12', 'MFCC_13',\n",
    "    'Chroma_1', 'Chroma_2', 'Chroma_3', 'Chroma_4', 'Chroma_5', 'Chroma_6', \n",
    "    'Chroma_7', 'Chroma_8', 'Chroma_9', 'Chroma_10', 'Chroma_11', 'Chroma_12',\n",
    "    'Spectral_Centroid', 'Spectral_Bandwidth', 'Rolloff', 'Zero_Crossing_Rate', 'RMSE'\n",
    "]\n",
    "\n",
    "X_train = df_train[features].values\n",
    "y_train = df_train['Speaker_ID'].values\n",
    "\n",
    "X_dev = df_dev[features].values\n",
    "y_dev = df_dev['Speaker_ID'].values\n",
    "\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test['Speaker_ID'].values\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_dev_scaled = scaler.transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_dev_enc = le.transform(y_dev)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "num_classes = len(np.unique(y_train_enc))\n",
    "y_train_cat = to_categorical(y_train_enc, num_classes=num_classes)\n",
    "y_dev_cat = to_categorical(y_dev_enc, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test_enc, num_classes=num_classes)\n",
    "\n",
    "\n",
    "timesteps = 20  \n",
    "features = 13  \n",
    "\n",
    "num_samples = X_train_scaled.shape[0]\n",
    "\n",
    "\n",
    "total_elements = X_train_scaled.shape[0] * X_train_scaled.shape[1]\n",
    "print(f\"Total elements in original data: {total_elements}\")\n",
    "\n",
    "\n",
    "required_elements = num_samples * timesteps * features\n",
    "print(f\"Required elements for reshaping: {required_elements}\")\n",
    "\n",
    "\n",
    "if total_elements % required_elements == 0:\n",
    "   \n",
    "    X_train_seq = X_train_scaled.reshape(num_samples, timesteps, features)\n",
    "    X_dev_seq = X_dev_scaled.reshape(X_dev_scaled.shape[0], timesteps, features)\n",
    "    X_test_seq = X_test_scaled.reshape(X_test_scaled.shape[0], timesteps, features)\n",
    "    \n",
    "    print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
    "    print(f\"X_dev_seq shape: {X_dev_seq.shape}\")\n",
    "    print(f\"X_test_seq shape: {X_test_seq.shape}\")\n",
    "else:\n",
    "    print(\"The total number of elements does not match the required number for reshaping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d916d-d5e8-46c0-b5e0-25318f865d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_seq shape: (28539, 1, 30)\n",
      "X_dev_seq shape: (2825, 1, 30)\n",
      "X_test_seq shape: (2913, 1, 30)\n"
     ]
    }
   ],
   "source": [
    "timesteps = 1  \n",
    "features = X_train_scaled.shape[1]  \n",
    "\n",
    "\n",
    "num_samples = X_train_scaled.shape[0]\n",
    "\n",
    "\n",
    "X_train_seq = X_train_scaled.reshape(num_samples, timesteps, features)\n",
    "X_dev_seq = X_dev_scaled.reshape(X_dev_scaled.shape[0], timesteps, features)\n",
    "X_test_seq = X_test_scaled.reshape(X_test_scaled.shape[0], timesteps, features)\n",
    "\n",
    "print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
    "print(f\"X_dev_seq shape: {X_dev_seq.shape}\")\n",
    "print(f\"X_test_seq shape: {X_test_seq.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc43a9-97a0-47a7-9da4-2e9d3dab8d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\opsb2\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">251</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,315</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m48,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m251\u001b[0m)                 │          \u001b[38;5;34m16,315\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">73,211</span> (285.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m73,211\u001b[0m (285.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">73,211</span> (285.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m73,211\u001b[0m (285.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1276 - loss: 4.5674 - val_accuracy: 0.6188 - val_loss: 1.6735\n",
      "Epoch 2/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6332 - loss: 1.5214 - val_accuracy: 0.8322 - val_loss: 0.7296\n",
      "Epoch 3/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7592 - loss: 0.9258 - val_accuracy: 0.8772 - val_loss: 0.5028\n",
      "Epoch 4/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.6786 - val_accuracy: 0.9002 - val_loss: 0.3893\n",
      "Epoch 5/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.5613 - val_accuracy: 0.8920 - val_loss: 0.3884\n",
      "Epoch 6/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.4957 - val_accuracy: 0.9122 - val_loss: 0.3242\n",
      "Epoch 7/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.4257 - val_accuracy: 0.9352 - val_loss: 0.2402\n",
      "Epoch 8/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3974 - val_accuracy: 0.9342 - val_loss: 0.2436\n",
      "Epoch 9/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3612 - val_accuracy: 0.9377 - val_loss: 0.2287\n",
      "Epoch 10/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.3314 - val_accuracy: 0.9437 - val_loss: 0.2049\n",
      "Epoch 11/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.3140 - val_accuracy: 0.9490 - val_loss: 0.1931\n",
      "Epoch 12/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2952 - val_accuracy: 0.9582 - val_loss: 0.1482\n",
      "Epoch 13/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2817 - val_accuracy: 0.9561 - val_loss: 0.1529\n",
      "Epoch 14/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2656 - val_accuracy: 0.9692 - val_loss: 0.1191\n",
      "Epoch 15/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2526 - val_accuracy: 0.9727 - val_loss: 0.1124\n",
      "Epoch 16/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2373 - val_accuracy: 0.9646 - val_loss: 0.1267\n",
      "Epoch 17/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.2406 - val_accuracy: 0.9703 - val_loss: 0.1152\n",
      "Epoch 18/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2184 - val_accuracy: 0.9742 - val_loss: 0.0997\n",
      "Epoch 19/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.2193 - val_accuracy: 0.9699 - val_loss: 0.1091\n",
      "Epoch 20/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.2179 - val_accuracy: 0.9798 - val_loss: 0.0828\n",
      "Epoch 21/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1985 - val_accuracy: 0.9784 - val_loss: 0.0872\n",
      "Epoch 22/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1941 - val_accuracy: 0.9763 - val_loss: 0.0911\n",
      "Epoch 23/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1912 - val_accuracy: 0.9699 - val_loss: 0.0998\n",
      "Epoch 24/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1850 - val_accuracy: 0.9731 - val_loss: 0.0924\n",
      "Epoch 25/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1745 - val_accuracy: 0.9770 - val_loss: 0.0836\n",
      "Epoch 26/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1779 - val_accuracy: 0.9823 - val_loss: 0.0681\n",
      "Epoch 27/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1578 - val_accuracy: 0.9869 - val_loss: 0.0556\n",
      "Epoch 28/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1646 - val_accuracy: 0.9795 - val_loss: 0.0736\n",
      "Epoch 29/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1585 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
      "Epoch 30/30\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1517 - val_accuracy: 0.9869 - val_loss: 0.0527\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9645 - loss: 0.1142\n",
      "Test Accuracy: 0.9670\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      1.00      1.00        97\n",
      "           8       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          18       1.00      0.99      1.00       116\n",
      "          19       1.00      0.88      0.94       127\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       1.00      1.00      1.00       114\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          38       0.99      1.00      0.99        95\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          60       1.00      0.84      0.91       112\n",
      "          64       0.00      0.00      0.00         0\n",
      "          67       1.00      0.98      0.99       107\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       1.00      0.99      1.00       102\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       1.00      0.97      0.99       103\n",
      "          82       1.00      0.96      0.98       128\n",
      "          84       0.99      0.95      0.97       129\n",
      "          86       1.00      1.00      1.00        56\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          97       0.99      0.96      0.98       110\n",
      "          98       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         115       1.00      0.97      0.98       127\n",
      "         118       1.00      1.00      1.00       123\n",
      "         119       1.00      0.98      0.99       119\n",
      "         120       1.00      0.96      0.98       113\n",
      "         121       0.00      0.00      0.00         0\n",
      "         126       1.00      1.00      1.00       119\n",
      "         132       1.00      0.95      0.97       113\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         155       1.00      0.99      1.00       111\n",
      "         162       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         177       1.00      0.96      0.98       112\n",
      "         183       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       1.00      1.00      1.00       108\n",
      "         196       0.99      0.89      0.94       133\n",
      "         203       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         220       1.00      0.98      0.99       103\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       1.00      0.97      0.99       118\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         0\n",
      "         240       0.00      0.00      0.00         0\n",
      "         241       0.99      1.00      1.00       118\n",
      "         244       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97      2913\n",
      "   macro avg       0.34      0.33      0.33      2913\n",
      "weighted avg       1.00      0.97      0.98      2913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\opsb2\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\opsb2\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\opsb2\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(1, 30)),  # 64 LSTM units\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_cat, \n",
    "                    epochs=30, batch_size=64,\n",
    "                    validation_data=(X_dev_seq, y_dev_cat))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_seq, y_test_cat)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(classification_report(y_test_enc, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad72d4-16b4-477c-bd5f-4994d55fccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = df_train.drop(columns=['Speaker_ID', 'Chapter_ID', 'File_Name'])\n",
    "X_test = df_test.drop(columns=['Speaker_ID', 'Chapter_ID', 'File_Name'])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['Speaker_ID'])\n",
    "y_test = le.transform(df_test['Speaker_ID'])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb03f3-5699-4976-83ec-f258276467b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\opsb2\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.0501 - loss: 4.6812 - val_accuracy: 0.1346 - val_loss: 3.5534\n",
      "Epoch 2/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.2127 - loss: 3.1265 - val_accuracy: 0.2204 - val_loss: 3.0194\n",
      "Epoch 3/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.3303 - loss: 2.5908 - val_accuracy: 0.3714 - val_loss: 2.4912\n",
      "Epoch 4/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.3846 - loss: 2.2932 - val_accuracy: 0.4157 - val_loss: 2.3031\n",
      "Epoch 5/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.4223 - loss: 2.1424 - val_accuracy: 0.4432 - val_loss: 2.1053\n",
      "Epoch 6/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.4530 - loss: 2.0130 - val_accuracy: 0.4555 - val_loss: 2.0474\n",
      "Epoch 7/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.4665 - loss: 1.9646 - val_accuracy: 0.4748 - val_loss: 1.9852\n",
      "Epoch 8/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.4870 - loss: 1.8721 - val_accuracy: 0.4885 - val_loss: 1.8643\n",
      "Epoch 9/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5093 - loss: 1.7685 - val_accuracy: 0.5084 - val_loss: 1.7833\n",
      "Epoch 10/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 1.7062 - val_accuracy: 0.5149 - val_loss: 1.7242\n",
      "Epoch 11/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5538 - loss: 1.6303 - val_accuracy: 0.5438 - val_loss: 1.6511\n",
      "Epoch 12/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5668 - loss: 1.5574 - val_accuracy: 0.5990 - val_loss: 1.4536\n",
      "Epoch 13/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5783 - loss: 1.5044 - val_accuracy: 0.5987 - val_loss: 1.4321\n",
      "Epoch 14/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.5969 - loss: 1.4537 - val_accuracy: 0.5987 - val_loss: 1.4405\n",
      "Epoch 15/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6088 - loss: 1.3918 - val_accuracy: 0.6135 - val_loss: 1.3787\n",
      "Epoch 16/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6225 - loss: 1.3419 - val_accuracy: 0.6725 - val_loss: 1.2113\n",
      "Epoch 17/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6352 - loss: 1.3066 - val_accuracy: 0.6656 - val_loss: 1.2206\n",
      "Epoch 18/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.6436 - loss: 1.2715 - val_accuracy: 0.6636 - val_loss: 1.2124\n",
      "Epoch 19/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6504 - loss: 1.2464 - val_accuracy: 0.6801 - val_loss: 1.1513\n",
      "Epoch 20/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6562 - loss: 1.2126 - val_accuracy: 0.6464 - val_loss: 1.2016\n",
      "Epoch 21/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6669 - loss: 1.1749 - val_accuracy: 0.6969 - val_loss: 1.0675\n",
      "Epoch 22/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.6768 - loss: 1.1429 - val_accuracy: 0.6780 - val_loss: 1.1147\n",
      "Epoch 23/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6763 - loss: 1.1352 - val_accuracy: 0.7182 - val_loss: 1.0124\n",
      "Epoch 24/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6851 - loss: 1.1079 - val_accuracy: 0.6965 - val_loss: 1.0411\n",
      "Epoch 25/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.6992 - loss: 1.0607 - val_accuracy: 0.7051 - val_loss: 0.9830\n",
      "Epoch 26/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.7016 - loss: 1.0427 - val_accuracy: 0.7367 - val_loss: 0.9168\n",
      "Epoch 27/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7061 - loss: 1.0299 - val_accuracy: 0.7367 - val_loss: 0.8977\n",
      "Epoch 28/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7127 - loss: 1.0140 - val_accuracy: 0.7473 - val_loss: 0.8928\n",
      "Epoch 29/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.7180 - loss: 0.9830 - val_accuracy: 0.7264 - val_loss: 0.9331\n",
      "Epoch 30/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7184 - loss: 0.9779 - val_accuracy: 0.7487 - val_loss: 0.8408\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.7647\n",
      "Test Accuracy: 0.7487126588821411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = df_train.drop(columns=['Speaker_ID', 'Chapter_ID', 'File_Name'])\n",
    "X_test = df_test.drop(columns=['Speaker_ID', 'Chapter_ID', 'File_Name'])\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['Speaker_ID'])\n",
    "y_test = le.transform(df_test['Speaker_ID'])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False), input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(le.classes_), activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "X_train = X_train[..., np.newaxis]  \n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8089b151-34ce-4607-83b0-3b24a13a5be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Training & Validation Accuracy/Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f40029-e9da-4aa8-97e7-5899dc1a4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras_tuner) (3.9.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras_tuner) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras_tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from optree->keras->keras_tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\opsb2\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def quick_model_builder(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "    \n",
    "    lstm_units = hp.Choice('lstm_units', values=[64, 128])\n",
    "    model.add(layers.Bidirectional(layers.LSTM(units=lstm_units)))\n",
    "\n",
    "    \n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.3, 0.5])\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    \n",
    "    dense_units = hp.Choice('dense_units', values=[64, 128])\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "\n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    \n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5a63d4e-cf90-43eb-87d4-5b46e63072ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257fe65-cd7a-452e-aae6-d234607480e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 07s]\n",
      "val_accuracy: 0.7346378564834595\n",
      "\n",
      "Best val_accuracy So Far: 0.7346378564834595\n",
      "Total elapsed time: 00h 09m 48s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    quick_model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  \n",
    "    directory='quick_tuning',\n",
    "    project_name='bilstm_quick'\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "tuner.search(X_train, y_train_cat,\n",
    "             epochs=15,\n",
    "             validation_data=(X_test, y_test_cat),\n",
    "             callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815c41f-f5a1-4ee4-925f-f65ce447520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Config:\n",
      "lstm_units: 64\n",
      "dense_units: 128\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.001\n",
      "Epoch 1/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.0704 - loss: 4.4571 - val_accuracy: 0.1878 - val_loss: 3.1308\n",
      "Epoch 2/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.3062 - loss: 2.6969 - val_accuracy: 0.3402 - val_loss: 2.4904\n",
      "Epoch 3/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.4110 - loss: 2.1937 - val_accuracy: 0.4325 - val_loss: 2.1102\n",
      "Epoch 4/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.4688 - loss: 1.9233 - val_accuracy: 0.4298 - val_loss: 2.0318\n",
      "Epoch 5/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5139 - loss: 1.7642 - val_accuracy: 0.4658 - val_loss: 1.9237\n",
      "Epoch 6/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5588 - loss: 1.5955 - val_accuracy: 0.5342 - val_loss: 1.6475\n",
      "Epoch 7/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5972 - loss: 1.4413 - val_accuracy: 0.5709 - val_loss: 1.5284\n",
      "Epoch 8/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6261 - loss: 1.3288 - val_accuracy: 0.6361 - val_loss: 1.2749\n",
      "Epoch 9/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6521 - loss: 1.2253 - val_accuracy: 0.6402 - val_loss: 1.2829\n",
      "Epoch 10/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6688 - loss: 1.1547 - val_accuracy: 0.6454 - val_loss: 1.2240\n",
      "Epoch 11/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6895 - loss: 1.0720 - val_accuracy: 0.6972 - val_loss: 1.0193\n",
      "Epoch 12/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.7097 - loss: 0.9982 - val_accuracy: 0.7013 - val_loss: 1.0220\n",
      "Epoch 13/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.7253 - loss: 0.9528 - val_accuracy: 0.7140 - val_loss: 0.9462\n",
      "Epoch 14/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7325 - loss: 0.9141 - val_accuracy: 0.7422 - val_loss: 0.8861\n",
      "Epoch 15/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7448 - loss: 0.8690 - val_accuracy: 0.7710 - val_loss: 0.7962\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Config:\")\n",
    "for param in ['lstm_units', 'dense_units', 'dropout_rate', 'learning_rate']:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")\n",
    "\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train_cat,\n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          epochs=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d3573-27dd-4707-8c70-1358ab56b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Attention layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        a = tf.keras.backend.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return tf.keras.backend.sum(output, axis=1)\n",
    "\n",
    "\n",
    "def build_bilstm_attention_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n",
    "    x = Attention()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906708b0-d89e-4f09-ab08-75a48f3c4b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">133,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">251</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,379</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m133,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │             \u001b[38;5;34m286\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m251\u001b[0m)                 │          \u001b[38;5;34m32,379\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,681</span> (776.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m198,681\u001b[0m (776.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,681</span> (776.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m198,681\u001b[0m (776.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.0266 - loss: 4.8491 - val_accuracy: 0.0899 - val_loss: 3.7836\n",
      "Epoch 2/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.1318 - loss: 3.6411 - val_accuracy: 0.1411 - val_loss: 3.3427\n",
      "Epoch 3/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.2337 - loss: 3.0628 - val_accuracy: 0.2853 - val_loss: 2.8357\n",
      "Epoch 4/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.3203 - loss: 2.6332 - val_accuracy: 0.3677 - val_loss: 2.3637\n",
      "Epoch 5/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.3899 - loss: 2.3048 - val_accuracy: 0.4257 - val_loss: 2.1349\n",
      "Epoch 6/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.4392 - loss: 2.1094 - val_accuracy: 0.4693 - val_loss: 2.0186\n",
      "Epoch 7/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.4732 - loss: 1.9429 - val_accuracy: 0.5132 - val_loss: 1.7472\n",
      "Epoch 8/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5178 - loss: 1.7917 - val_accuracy: 0.5990 - val_loss: 1.4798\n",
      "Epoch 9/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.5535 - loss: 1.6426 - val_accuracy: 0.6097 - val_loss: 1.3973\n",
      "Epoch 10/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.5884 - loss: 1.5157 - val_accuracy: 0.6169 - val_loss: 1.3521\n",
      "Epoch 11/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6013 - loss: 1.4415 - val_accuracy: 0.6395 - val_loss: 1.2434\n",
      "Epoch 12/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.6291 - loss: 1.3312 - val_accuracy: 0.6595 - val_loss: 1.1826\n",
      "Epoch 13/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6403 - loss: 1.2747 - val_accuracy: 0.6917 - val_loss: 1.0689\n",
      "Epoch 14/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.6586 - loss: 1.2150 - val_accuracy: 0.7168 - val_loss: 0.9786\n",
      "Epoch 15/15\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.6696 - loss: 1.1654 - val_accuracy: 0.7329 - val_loss: 0.9278\n"
     ]
    }
   ],
   "source": [
    "model = build_bilstm_attention_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=251)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=251)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=251)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    validation_data=(X_test, y_test_one_hot),\n",
    "                    epochs=15,\n",
    "                    batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b0157975-4b6e-49fc-903e-95c53f36a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6902 - loss: 1.0944 - val_accuracy: 0.7418 - val_loss: 0.8571\n",
      "Epoch 2/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7061 - loss: 1.0342 - val_accuracy: 0.7645 - val_loss: 0.8159\n",
      "Epoch 3/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7171 - loss: 0.9985 - val_accuracy: 0.7635 - val_loss: 0.7967\n",
      "Epoch 4/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7344 - loss: 0.9395 - val_accuracy: 0.7741 - val_loss: 0.7484\n",
      "Epoch 5/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7360 - loss: 0.9126 - val_accuracy: 0.7975 - val_loss: 0.6697\n",
      "Epoch 6/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7514 - loss: 0.8566 - val_accuracy: 0.7800 - val_loss: 0.7143\n",
      "Epoch 7/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7548 - loss: 0.8268 - val_accuracy: 0.8332 - val_loss: 0.5617\n",
      "Epoch 8/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7685 - loss: 0.7974 - val_accuracy: 0.8239 - val_loss: 0.5822\n",
      "Epoch 9/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7800 - loss: 0.7656 - val_accuracy: 0.8352 - val_loss: 0.5519\n",
      "Epoch 10/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7835 - loss: 0.7320 - val_accuracy: 0.8500 - val_loss: 0.5054\n",
      "Epoch 11/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 0.6896 - val_accuracy: 0.8469 - val_loss: 0.4972\n",
      "Epoch 12/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.8014 - loss: 0.6649 - val_accuracy: 0.8483 - val_loss: 0.4817\n",
      "Epoch 13/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.6380 - val_accuracy: 0.8623 - val_loss: 0.4557\n",
      "Epoch 14/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.6244 - val_accuracy: 0.8764 - val_loss: 0.4212\n",
      "Epoch 15/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8189 - loss: 0.5987 - val_accuracy: 0.8685 - val_loss: 0.4165\n",
      "Epoch 16/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8260 - loss: 0.5770 - val_accuracy: 0.8843 - val_loss: 0.3770\n",
      "Epoch 17/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.5561 - val_accuracy: 0.8853 - val_loss: 0.3580\n",
      "Epoch 18/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8318 - loss: 0.5468 - val_accuracy: 0.9053 - val_loss: 0.3231\n",
      "Epoch 19/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8456 - loss: 0.4995 - val_accuracy: 0.9059 - val_loss: 0.3184\n",
      "Epoch 20/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8528 - loss: 0.4864 - val_accuracy: 0.9118 - val_loss: 0.2879\n",
      "Epoch 21/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.8538 - loss: 0.4707 - val_accuracy: 0.9231 - val_loss: 0.2537\n",
      "Epoch 22/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.8563 - loss: 0.4584 - val_accuracy: 0.9210 - val_loss: 0.2804\n",
      "Epoch 23/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.8658 - loss: 0.4363 - val_accuracy: 0.9234 - val_loss: 0.2517\n",
      "Epoch 24/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8647 - loss: 0.4351 - val_accuracy: 0.9300 - val_loss: 0.2229\n",
      "Epoch 25/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8654 - loss: 0.4223 - val_accuracy: 0.9427 - val_loss: 0.2037\n",
      "Epoch 26/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8702 - loss: 0.4019 - val_accuracy: 0.9358 - val_loss: 0.2154\n",
      "Epoch 27/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8726 - loss: 0.3968 - val_accuracy: 0.9464 - val_loss: 0.1901\n",
      "Epoch 28/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8809 - loss: 0.3701 - val_accuracy: 0.9513 - val_loss: 0.1696\n",
      "Epoch 29/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.8773 - loss: 0.3838 - val_accuracy: 0.9296 - val_loss: 0.2203\n",
      "Epoch 30/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8847 - loss: 0.3455 - val_accuracy: 0.9564 - val_loss: 0.1474\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history =  model.fit(X_train, y_train_one_hot,\n",
    "                    validation_data=(X_test, y_test_one_hot),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88331bd-60b1-4484-aba6-1b6c5db45257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m889/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8862 - loss: 0.3454\n",
      "Epoch 1: val_loss improved from inf to 0.13411, saving model to best_bilstm_attention_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8862 - loss: 0.3455 - val_accuracy: 0.9643 - val_loss: 0.1341\n",
      "Epoch 2/30\n",
      "\u001b[1m890/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8898 - loss: 0.3417\n",
      "Epoch 2: val_loss did not improve from 0.13411\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8898 - loss: 0.3417 - val_accuracy: 0.9574 - val_loss: 0.1404\n",
      "Epoch 3/30\n",
      "\u001b[1m890/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8929 - loss: 0.3288\n",
      "Epoch 3: val_loss did not improve from 0.13411\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8929 - loss: 0.3288 - val_accuracy: 0.9616 - val_loss: 0.1372\n",
      "Epoch 4/30\n",
      "\u001b[1m891/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8988 - loss: 0.3153\n",
      "Epoch 4: val_loss did not improve from 0.13411\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8988 - loss: 0.3154 - val_accuracy: 0.9561 - val_loss: 0.1356\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_bilstm_attention_model.h5',  \n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_one_hot,\n",
    "    validation_data=(X_test, y_test_one_hot),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f9032a92-7d58-4f05-91d1-8fc9d02415ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_bilstm_attention_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda5bc3-12db-47ad-8a48-fb914bb5c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.0346 - loss: 4.7860 - val_accuracy: 0.0687 - val_loss: 3.9945\n",
      "Epoch 2/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.1883 - loss: 3.3790 - val_accuracy: 0.2345 - val_loss: 3.1505\n",
      "Epoch 3/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.3432 - loss: 2.5700 - val_accuracy: 0.3845 - val_loss: 2.4002\n",
      "Epoch 4/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.4859 - loss: 1.9540 - val_accuracy: 0.4782 - val_loss: 1.9760\n",
      "Epoch 5/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.5642 - loss: 1.6082 - val_accuracy: 0.5287 - val_loss: 1.7440\n",
      "Epoch 6/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.6170 - loss: 1.3939 - val_accuracy: 0.5647 - val_loss: 1.6197\n",
      "Epoch 7/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.6674 - loss: 1.2101 - val_accuracy: 0.5946 - val_loss: 1.4565\n",
      "Epoch 8/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.6979 - loss: 1.0870 - val_accuracy: 0.6165 - val_loss: 1.3831\n",
      "Epoch 9/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.7306 - loss: 0.9787 - val_accuracy: 0.7089 - val_loss: 1.0587\n",
      "Epoch 10/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.7664 - loss: 0.8465 - val_accuracy: 0.7422 - val_loss: 0.9180\n",
      "Epoch 11/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.7880 - loss: 0.7728 - val_accuracy: 0.7535 - val_loss: 0.8682\n",
      "Epoch 12/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8097 - loss: 0.6755 - val_accuracy: 0.7508 - val_loss: 0.8572\n",
      "Epoch 13/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8297 - loss: 0.6124 - val_accuracy: 0.7975 - val_loss: 0.7148\n",
      "Epoch 14/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8412 - loss: 0.5643 - val_accuracy: 0.7975 - val_loss: 0.6902\n",
      "Epoch 15/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8593 - loss: 0.5015 - val_accuracy: 0.8555 - val_loss: 0.5339\n",
      "Epoch 16/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.8795 - loss: 0.4346 - val_accuracy: 0.8562 - val_loss: 0.5015\n",
      "Epoch 17/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.8899 - loss: 0.3938 - val_accuracy: 0.8692 - val_loss: 0.4528\n",
      "Epoch 18/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.8994 - loss: 0.3588 - val_accuracy: 0.8926 - val_loss: 0.3996\n",
      "Epoch 19/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9147 - loss: 0.3134 - val_accuracy: 0.8867 - val_loss: 0.3792\n",
      "Epoch 20/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9224 - loss: 0.2871 - val_accuracy: 0.9080 - val_loss: 0.3410\n",
      "Epoch 21/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9288 - loss: 0.2576 - val_accuracy: 0.9015 - val_loss: 0.3380\n",
      "Epoch 22/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9392 - loss: 0.2352 - val_accuracy: 0.9310 - val_loss: 0.2576\n",
      "Epoch 23/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9470 - loss: 0.2041 - val_accuracy: 0.9231 - val_loss: 0.2845\n",
      "Epoch 24/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9562 - loss: 0.1787 - val_accuracy: 0.9341 - val_loss: 0.2396\n",
      "Epoch 25/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9572 - loss: 0.1668 - val_accuracy: 0.9564 - val_loss: 0.1820\n",
      "Epoch 26/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.9608 - loss: 0.1513 - val_accuracy: 0.9578 - val_loss: 0.1743\n",
      "Epoch 27/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.9713 - loss: 0.1271 - val_accuracy: 0.9458 - val_loss: 0.2085\n",
      "Epoch 28/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.9725 - loss: 0.1184 - val_accuracy: 0.9458 - val_loss: 0.1974\n",
      "Epoch 29/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.1041 - val_accuracy: 0.9691 - val_loss: 0.1364\n",
      "Epoch 30/30\n",
      "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9805 - loss: 0.0950 - val_accuracy: 0.9626 - val_loss: 0.1489\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Attention, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "input_shape = X_train.shape[1:]  \n",
    "num_classes = y_train_one_hot.shape[1]\n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "lstm_out = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n",
    "attention_out = Attention()([lstm_out, lstm_out])  # Correct usage: list of [query, value]\n",
    "output = Dense(num_classes, activation='softmax')(attention_out[:, -1, :])  # Pick last timestep after attention\n",
    "\n",
    "model = Model(inputs, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_bilstm_attention_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_one_hot,\n",
    "    validation_data=(X_test, y_test_one_hot),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b5927672-9d4c-4486-886a-5e0e5f202896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.1297\n",
      "Test Accuracy: 0.9691, Test Loss: 0.1364\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ccf259d1-423d-45ea-b2a8-1561bd0d983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.1297\n",
      "Test Accuracy: 0.9691, Test Loss: 0.1364\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5729748b-0800-4cbb-b0e0-c98558465e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "try:\n",
    "    model = load_model(\"best_bilstm_attention_model.keras\")\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66779a3d-c7f7-47b0-9a9e-33199ef734db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "try:\n",
    "    model = load_model(\"best_bilstm_attention_model.keras\")\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85147585-84be-414e-a579-639c3736f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
      "Predicted Speaker_ID: 227\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_bilstm_attention_model.keras\")\n",
    "\n",
    "\n",
    "audio_path = \"61-70968-0001.wav\"  \n",
    "\n",
    "\n",
    "y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "\n",
    "if mfcc.shape[1] < 30:\n",
    "    pad_width = 30 - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0,0),(0, pad_width)), mode='constant')\n",
    "else:\n",
    "    mfcc = mfcc[:, :30]\n",
    "\n",
    "\n",
    "mfcc_mean = np.mean(mfcc, axis=0)\n",
    "\n",
    "\n",
    "input_data = mfcc_mean.reshape(1, 30, 1)\n",
    "\n",
    "\n",
    "prediction = model.predict(input_data)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "print(f\"Predicted Speaker_ID: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66142e39-fb17-4e29-b13f-da501b85dfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
